{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024c4441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "[nltk_data] Downloading package punkt to /home/skunk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84203714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unieval',\n",
       " 'bertscorefree',\n",
       " 'bartcnnscore',\n",
       " 'bartscore_pegasus_cnndm',\n",
       " 'bartscore_pegasus_newsroom',\n",
       " 'bartscore_pegasus_xsum']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['unieval', 'bertscorefree', 'bartcnnscore', 'bartscore_pegasus_cnndm', 'bartscore_pegasus_newsroom', 'bartscore_pegasus_xsum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f7ba1",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bddc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e78b7a",
   "metadata": {},
   "source": [
    "SummEval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd94afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summeval']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ba10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/llmthonskdir/metrics/data/cnndm/model_annotations.aligned.paired.jsonl'\n",
    "with open(file_path, 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "data_temp={}\n",
    "for i in range(len(json_list)):\n",
    "    data_temp[i] = json.loads(json_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42190680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summeval']['srcs'] = [data_temp[key]['text'] for key in set(data_temp)]\n",
    "data['summeval']['hyps'] = [data_temp[key]['decoded'] for key in set(data_temp)]\n",
    "data['summeval']['refs'] = [data_temp[key]['references'] for key in set(data_temp)]\n",
    "data['summeval']['annot'] = {}\n",
    "data['summeval']['annot']['coh'] = [pd.DataFrame(data_temp[key]['expert_annotations'])['coherence'].mean() for key in set(data_temp)]\n",
    "data['summeval']['annot']['con'] = [pd.DataFrame(data_temp[key]['expert_annotations'])['consistency'].mean() for key in set(data_temp)]\n",
    "data['summeval']['annot']['flu'] = [pd.DataFrame(data_temp[key]['expert_annotations'])['fluency'].mean() for key in set(data_temp)]\n",
    "data['summeval']['annot']['rel'] = [pd.DataFrame(data_temp[key]['expert_annotations'])['relevance'].mean() for key in set(data_temp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ffabf",
   "metadata": {},
   "source": [
    "Newsroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2ff53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['newsroom']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e098125",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/llmthonskdir/metrics/data/BARTScore/SUM/Newsroom/data.pkl', 'rb') as f:\n",
    "    data_temp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb715a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['newsroom']['srcs']=[]\n",
    "data['newsroom']['hyps']=[]\n",
    "data['newsroom']['refs']=[]\n",
    "data['newsroom']['annot']={}\n",
    "data['newsroom']['annot']['coh'] = []\n",
    "data['newsroom']['annot']['info'] = []\n",
    "data['newsroom']['annot']['flu'] = []\n",
    "data['newsroom']['annot']['rel'] = []\n",
    "\n",
    "for key in set(data_temp):\n",
    "    for system in set(data_temp[key]['sys_summs']):     \n",
    "        data['newsroom']['srcs'].append(data_temp[key]['src'])\n",
    "        data['newsroom']['hyps'].append(data_temp[key]['sys_summs'][system]['sys_summ'])\n",
    "        data['newsroom']['refs'].append(data_temp[key]['ref_summ'])\n",
    "        data['newsroom']['annot']['coh'].append(data_temp[key]['sys_summs'][system]['scores']['coherence'])\n",
    "        data['newsroom']['annot']['info'].append(data_temp[key]['sys_summs'][system]['scores']['informativeness'])\n",
    "        data['newsroom']['annot']['flu'].append(data_temp[key]['sys_summs'][system]['scores']['fluency'])\n",
    "        data['newsroom']['annot']['rel'].append(data_temp[key]['sys_summs'][system]['scores']['relevance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8ccdc",
   "metadata": {},
   "source": [
    "QAGS-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac10a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['qagscnn']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8867665",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/llmthonskdir/metrics/data/BARTScore/SUM/QAGS_CNN/data.pkl', 'rb') as f:\n",
    "    data_temp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67cd9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['qagscnn']['srcs']=[]\n",
    "data['qagscnn']['hyps']=[]\n",
    "data['qagscnn']['refs']=[]\n",
    "data['qagscnn']['annot']={}\n",
    "data['qagscnn']['annot']['fact'] = []\n",
    "\n",
    "for key in set(data_temp):\n",
    "    for system in set(data_temp[key]['sys_summs']):     \n",
    "        data['qagscnn']['srcs'].append(data_temp[key]['src'])\n",
    "        data['qagscnn']['hyps'].append(data_temp[key]['sys_summs'][system]['sys_summ'])\n",
    "        data['qagscnn']['refs'].append(data_temp[key]['ref_summ'])\n",
    "        data['qagscnn']['annot']['fact'].append(data_temp[key]['sys_summs'][system]['scores']['fact'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286b9e6",
   "metadata": {},
   "source": [
    "QAGS-XSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f0c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['qagsxsum']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac8bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/llmthonskdir/metrics/data/BARTScore/SUM/QAGS_XSUM/data.pkl', 'rb') as f:\n",
    "    data_temp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0500d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['qagsxsum']['srcs']=[]\n",
    "data['qagsxsum']['hyps']=[]\n",
    "data['qagsxsum']['refs']=[]\n",
    "data['qagsxsum']['annot']={}\n",
    "data['qagsxsum']['annot']['fact'] = []\n",
    "\n",
    "for key in set(data_temp):\n",
    "    for system in set(data_temp[key]['sys_summs']):     \n",
    "        data['qagsxsum']['srcs'].append(data_temp[key]['src'])\n",
    "        data['qagsxsum']['hyps'].append(data_temp[key]['sys_summs'][system]['sys_summ'])\n",
    "        data['qagsxsum']['refs'].append(data_temp[key]['ref_summ'])\n",
    "        data['qagsxsum']['annot']['fact'].append(data_temp[key]['sys_summs'][system]['scores']['fact'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df8516",
   "metadata": {},
   "source": [
    "HallXSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "908e57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hallxsum']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ed5bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"xsum\")\n",
    "xsum_data = pd.concat((pd.DataFrame(dataset['train']),\n",
    "                       pd.DataFrame(dataset['validation']),\n",
    "                       pd.DataFrame(dataset['test'])), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af7f658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = pd.read_csv('/llmthonskdir/metrics/data/xsum_hallucination_annotations/factuality_annotations_xsum_summaries.csv')\n",
    "data_temp['fact'] = data_temp['is_factual'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "data_temp = data_temp[['fact','bbcid','system','summary']].groupby(['bbcid','system','summary']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbde685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1869/1869 [00:35<00:00, 52.99it/s]\n"
     ]
    }
   ],
   "source": [
    "data['hallxsum']['srcs']=[]\n",
    "data['hallxsum']['hyps']=[]\n",
    "data['hallxsum']['refs']=[]\n",
    "data['hallxsum']['annot']={}\n",
    "data['hallxsum']['annot']['fact'] = []\n",
    "\n",
    "for i in tqdm(range(data_temp.shape[0])):\n",
    "    row=xsum_data[np.array(xsum_data.id).astype(int)==data_temp.iloc[i]['bbcid']]\n",
    "    \n",
    "    data['hallxsum']['srcs'].append(row.iloc[0].document)\n",
    "    data['hallxsum']['hyps'].append(data_temp.iloc[i]['summary'])\n",
    "    data['hallxsum']['refs'].append(row.iloc[0].summary)\n",
    "    data['hallxsum']['annot']['fact'].append(data_temp.iloc[i]['fact'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fe583",
   "metadata": {},
   "source": [
    "### Extracting metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c81e3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(str, 'hallxsum'),\n",
       " (str, 'newsroom'),\n",
       " (str, 'qagscnn'),\n",
       " (str, 'qagsxsum'),\n",
       " (list, 'summeval')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(type(data[key]['refs'][0]),key) for key in set(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed1eeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in set(data):\n",
    "    if key=='summeval':\n",
    "        pass\n",
    "    else:\n",
    "        data[key]['refs'] = [[r] for r in data[key]['refs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d5db1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in set(data):\n",
    "    data[key]['metrics'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffa7ba",
   "metadata": {},
   "source": [
    "BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a81c36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e19de98a3f437085bb3089f3057223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b5f992b5744bd5847a76a6dd3c0c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e43b23d7f941a88d68036bab7cbe7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bc9d4ce88a41cf8acf32454230620a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5a06eaf9534cbeb831894fb3f3870f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 32 s, total: 2min 38s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bert_scorer = BERTScorerOurs()\n",
    "\n",
    "for key in data.keys():\n",
    "    data[key]['metrics']['bertscorefree'] = bert_scorer.score(data[key]['hyps'], [[s] for s in data[key]['srcs']], agg=\"mean\", batch_size=16) \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898af1bc",
   "metadata": {},
   "source": [
    "BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a56cae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summeval\n",
      "newsroom\n",
      "qagscnn\n",
      "qagsxsum\n",
      "hallxsum\n",
      "CPU times: user 2min 33s, sys: 1.33 s, total: 2min 34s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bartcnn_scorer = BARTScorer(checkpoint='facebook/bart-large-cnn')\n",
    "\n",
    "for key in data.keys():\n",
    "    print(key)\n",
    "    data[key]['metrics']['bartcnnscore'] = bartcnn_scorer.score(data[key]['srcs'], data[key]['hyps'], batch_size=16) \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6110889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-newsroom and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 13s, sys: 9.68 s, total: 8min 23s\n",
      "Wall time: 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "checkpoints = ['google/pegasus-cnn_dailymail', 'google/pegasus-newsroom', 'google/pegasus-xsum'] #', \n",
    "names = {'google/pegasus-cnn_dailymail':'cnndm', 'google/pegasus-newsroom':'newsroom', 'google/pegasus-xsum':'xsum'}\n",
    "max_lengths = {'google/pegasus-cnn_dailymail':1024, 'google/pegasus-newsroom':512, 'google/pegasus-xsum':512}\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    scorer = PegasusScorer(device='cuda', max_length=max_lengths[checkpoint], checkpoint=checkpoint)\n",
    "\n",
    "    for key in data.keys():\n",
    "        data[key]['metrics']['bartscore_pegasus_'+names[checkpoint]] = scorer.score(data[key]['srcs'], data[key]['hyps'], batch_size=8) \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7497309",
   "metadata": {},
   "source": [
    "Unieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20d1781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summeval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f61f49ee2446892ffb9faca0011d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f961656bc00044b09a3f88efc1a4d7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22a8753354b4674b0f9c53150f5eda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fc90e4a0e74abbb3819e3d92ccfac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5713b6d7fe5f47beb04e284f84cb5159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37e65cab74f40b5af242d145847a032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:54<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 624/624 [05:06<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 624/624 [00:34<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:30<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:29<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:29<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:28<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:29<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:28<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:28<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:28<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:29<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1600 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:29<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsroom\n",
      "Evaluating coherence of 420 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:49<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 420 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [01:31<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 420 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [00:07<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 420 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:08<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qagscnn\n",
      "Evaluating coherence of 235 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:17<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 235 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:44<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 235 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:04<00:00, 18.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 235 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:17<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qagsxsum\n",
      "Evaluating coherence of 239 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:24<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 239 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:24<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 239 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 239 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:24<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallxsum\n",
      "Evaluating coherence of 1869 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [02:38<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 1869 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 237/237 [02:37<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 1869 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 237/237 [00:12<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 1869 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:17<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 21s, sys: 12min 51s, total: 31min 13s\n",
      "Wall time: 26min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unieval_scorer = UniEvalScorerOurs()\n",
    "\n",
    "for key in data.keys():\n",
    "    print(key)\n",
    "    data[key]['metrics']['unieval'] = unieval_scorer.score(data[key]['srcs'], data[key]['hyps'], data[key]['refs'], agg=\"mean\") \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2525e",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd77990",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/data.pkl\",\"wb\")\n",
    "pickle.dump(data,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eba146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
